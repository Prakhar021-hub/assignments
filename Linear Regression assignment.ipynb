{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ffc2b7c-0967-417b-be21-0d0fb88aa219",
   "metadata": {},
   "source": [
    "1. What is Simple Linear Regression\n",
    "- Ans :Simple Linear Regression is a method used to model the relationship between one independent variable (X) and one dependent variable (Y) by fitting a straight line (Y = mX + c) to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c61c4f5-acf9-4362-bff2-e4021616d728",
   "metadata": {},
   "source": [
    "2. What are the key assumptions of Simple Linear Regression\n",
    "- Ans: The key assumptions of simple linear regression are as followss-\n",
    "   * Linearity between X and Y\n",
    "   * Independence of observations\n",
    "   * Homoscedasticity (constant variance of errors)\n",
    "   * Normally distributed residuals (errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aae008-2d97-4b59-8611-b35daaa5fdb5",
   "metadata": {},
   "source": [
    "3. What does the coefficient m represent in the equation Y = mX + c\n",
    "- Ans: m is the slope of the line; it indicates the change in Y for a one-unit increase in X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e35182-98a8-49ca-9cde-f524faae1aef",
   "metadata": {},
   "source": [
    "4. What does the intercept *c* represent in the equation Y = mX + c\n",
    "- Ans: c is the value of Y when X is 0; it represents the point where the line crosses the Y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8350862e-b811-400b-ab16-816407b9dabe",
   "metadata": {},
   "source": [
    "5. How do we calculate the slope m in Simple Linear Regression\n",
    "- Ans: the value of slome m can be calculated by the formula   y2-y1/x2-x1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81e1114-b785-400f-986b-29ba53ebf072",
   "metadata": {},
   "source": [
    "6. What is the purpose of the least squares method in Simple Linear Regression\n",
    "- Ans: It minimizes the sum of the squared differences between the observed values and the predicted values to find the best-fitting line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c56a036-0a6d-4cbb-b1b3-96cd69c79ede",
   "metadata": {},
   "source": [
    "7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression\n",
    "- Ans: R² measures the proportion of variance in Y explained by X. It ranges from 0 to 1, with higher values indicating a better fit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3758da-ea62-498b-9472-3141e45e7528",
   "metadata": {},
   "source": [
    "8. What is Multiple Linear Regression\n",
    "- Ans: Multiple Linear Regression models the relationship between one dependent variable and two or more independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f14b23c-0ba2-49a0-ab04-118e99a4b4d9",
   "metadata": {},
   "source": [
    "9. What is the main difference between Simple and Multiple Linear Regression\n",
    "- Ans: Simple Linear Regression uses one independent variable; Multiple Linear Regression uses two or more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4894e72-a0b4-4d11-ba58-3e4aa5e36912",
   "metadata": {},
   "source": [
    "10. What are the key assumptions of Multiple Linear Regression\n",
    "- Ans: the key assumptions of multiple linear regression are:\n",
    "\n",
    "* Linearity between dependent and independent variables\n",
    "* Independence of errors\n",
    "* Homoscedasticity\n",
    "* Normal distribution of errors\n",
    "* No multicollinearity among independent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9ce305-335c-4219-a3a2-f694a88e672c",
   "metadata": {},
   "source": [
    "11. *What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression modeAns:*\r",
    "- Ans:   Heteroscedasticity means the variance of the residuals is not constant. It can lead to inefficient estimates and unreliable hypothesis tests (e.g., t-test1s)all these in a downloadable format or expanded explanations!\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb232fe-5054-44e8-987d-14ebcfe1023e",
   "metadata": {},
   "source": [
    "12. **How can you improve a Multiple Linear Regression model with high multicollineaAns: Theough following techniques : rity**\n",
    "- Ans:\n",
    "   * Remove or combine correlated variables\n",
    "   * Use Principal Component Analysis (PCA)\n",
    "   * Apply Ridge or Lasso r1egression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe88bb2-bd76-43cc-9e51-6cd6415216e4",
   "metadata": {},
   "source": [
    "13. **What are some common techniques for transforming categorical variables for use in regressAns:ion models**\n",
    "- Ans:\n",
    "   * One-hot encoding\n",
    "   * Label encoding\n",
    "   * Dummy variable creation (for bin1ary categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90fc5dd-36cb-40db-9f10-dcb46b4e9ca3",
   "metadata": {},
   "source": [
    "14. **What is the role of interaction terms in Multiple LAns: ar Regression**\n",
    "- Ans:   Interaction terms model the combined effect of two variables on the dependent variable, revealing relationships not captured by1 individual terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7dfefe-df03-459f-9483-4bced87615b1",
   "metadata": {},
   "source": [
    "15. **How can the interpretation of intercept differ between Simple and MultiplAns:Linear Regression**\n",
    "- Ans:  In Simple Linear Regression, the intercept is the predicted value when X = 0.\n",
    "   In Multiple Linear Regression, it’s the predicted Y when **all** independent variables are zero, which may not always be meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ed1d24-a8ac-4546-980a-dbdff33bf2e5",
   "metadata": {},
   "source": [
    "16. **What is the significance of the slope in regression analysis, and how doeAns: it affect predictions**\n",
    "-  Ans:  The slope shows how much Y changes with a one-unit change in X. It directly impacts the model’s prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86cbc86-5420-4400-a417-519340776a5c",
   "metadata": {},
   "source": [
    "17. **What are the limitations of using R² as a sole measure of model performance**\n",
    "- Ans:\n",
    "   * It doesn’t account for overfitting\n",
    "   * It doesn’t indicate whether variables are statistically significant\n",
    "   * It doesn’t reflect model accuracy on unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0bd9eb-f03e-47d9-891a-3cdc21d8d5aa",
   "metadata": {},
   "source": [
    "\n",
    "18. **How would you interpret a large standard error for a regression coefficient**\n",
    "- Ans:  It suggests the coefficient is unstable and possibly not statistically significant, indicating high variability or poor model fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba431b82-2adf-4f83-879a-fbf23a50c8e3",
   "metadata": {},
   "source": [
    "19. **What is polynomial regression**\n",
    "- Ans:   Polynomial regression models nonlinear relationships by including powers of the independent variable (e.g., $X^2, X^3$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff7deb9-6a51-4c17-9586-197e83abb458",
   "metadata": {},
   "source": [
    "21. **How does the intercept in a regression model provide context for the relationship between variables**\n",
    " - Ans:    It serves as the baseline value of Y when all independent variables are zero, helping interpret the starting point of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e21a710-568d-4bbd-be26-2cc7dcc44d4d",
   "metadata": {},
   "source": [
    "22. **How can heteroscedasticity be identified in residual plots, and why is it important to address it**\n",
    "- Ans:    Look for a funnel shape (widening or narrowing spread) in residuals vs. fitted values plot. It’s important to fix it to ensure valid inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a65191-03fd-4064-923a-0667bdebf994",
   "metadata": {},
   "source": [
    "23. **What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²**\n",
    "- Ans:   It means that added variables may not be contributing meaningfully and could be causing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f370dd-9d19-4178-a02a-5dbe7853734e",
   "metadata": {},
   "source": [
    "24. **Why is it important to scale variables in Multiple Linear Regression**\n",
    "- Ans:    Scaling ensures that variables with large magnitudes don’t dominate the model and is critical for algorithms like Ridge or Lasso regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfb4bda-2833-4a47-9a11-084e88689550",
   "metadata": {},
   "source": [
    "25. **How does polynomial regression differ from linear regression**\n",
    "- Ans:   Linear regression fits a straight line, while polynomial regression fits a curved line by including higher-order terms of the predictorine by including higher-order terms of the predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c2e7fc-5268-48ad-b555-7a7f699a85a0",
   "metadata": {},
   "source": [
    "26. **What is the general equation for polynomial regression**\n",
    "- Ans: Y = a0 + a1X^1 + a2.X^2 +a3.X^3 + ......+ anX^n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1efe3f-385b-49eb-b643-d66b341cf185",
   "metadata": {},
   "source": [
    "27. **Can polynomial regression be applied to multiple variables**\n",
    "- Ans   Yes, this is called **multivariate polynomial regression**, where each variable can have polynomial terms and interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9192e1-7825-4a29-8ca7-79a433c0b46d",
   "metadata": {},
   "source": [
    "28. **What are the limitations of polynomial regression**\n",
    "- Ans: \n",
    "   * High-degree models can overfit\n",
    "   * Poor extrapolation outside the data range\n",
    "   * Increased complexity and risk of multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c256ae-5c62-4922-b155-21e43c3a918e",
   "metadata": {},
   "source": [
    "29. **What methods can be used to evaluate model fit when selecting the degree of a polynomial**\n",
    "- Ans: \n",
    "   * Cross-validation\n",
    "   * Adjusted R²\n",
    "   * AIC/BIC (Akaike/Bayesian Information Criterion)\n",
    "   * Residual plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6fe3d2-cd00-402c-afd2-bc23d3cfdafa",
   "metadata": {},
   "source": [
    "30. **Why is visualization important in polynomial regression**\n",
    "- Ans:  It helps detect overfitting, underfitting, and understand how well the curve fits the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d649efcd-e062-4215-8849-7e4c842303e9",
   "metadata": {},
   "source": [
    "31. **How is polynomial regression implemented in Python**\n",
    " - Ans:   **Using scikit-learn**\n",
    "\n",
    "  //Code \n",
    "  \n",
    "   from sklearn.preprocessing import PolynomialFeatures\n",
    "   from sklearn.linear_model import LinearRegression\n",
    "   from sklearn.pipeline import make_pipeline\n",
    "\n",
    "   model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "   model.fit(X_train, y_train)\n",
    "   predictions = model.predict(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Customer Categorizer)",
   "language": "python",
   "name": "customer_categorizer_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
